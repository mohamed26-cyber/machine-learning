{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| Luca Mossina and [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en) | <a href=\"https://supaerodatascience.github.io/machine-learning/\">https://supaerodatascience.github.io/machine-learning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f04d09ee-0e3c-4a24-b3ce-345323c1ce23"
    }
   },
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">An application of SVMs in Multi-Label Classification (MLC)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see an application which is both harder and less common than binary classification, that of **multi-label classification** (MLC).  \n",
    "Given a list of possible labels, the problem consists in finding one **or more** labels associated to a data point.  \n",
    "For instance, imagine extracting the key topics from a newspaper article, or classifing the elements composing an image. Possibly many labels can be associated to each item.\n",
    "\n",
    "Given a set of labels $\\mathcal{L} = \\{l_1, l_2, ..., l_k\\} \\in \\{0,1\\}^k$, we want to map elements of a feature space $\\mathcal{X}$ to a subset of $\\mathcal{L}$:  \n",
    "\n",
    "$$h : \\mathcal{X} \\longrightarrow \\mathcal{P}(\\mathcal{L})$$\n",
    "\n",
    "The two typical approaches for such problems are known as **Binary Relevance** (BR) and **Label Powerset** (LP).  \n",
    "\n",
    " - BR: each label in $\\mathcal{L}$ is a binary classification problem, $h_{i} : \\mathcal{X} \\longrightarrow l_{i}, l_{i} \\in \\{0,1\\}, i = 1, ..., |\\mathcal{L}|$.  \n",
    " This method ignores any correlation between labels (supposes them independent).\n",
    "\n",
    " - LP: transforms a problem of MLC into one of multiclass classification, mapping elements $x \\in \\mathcal{X}$ directly to $s \\in \\mathcal{P}(\\mathcal{L})$.  \n",
    " This method becomes rapidly inapplicable as the number of elemnts in $\\mathcal{P}(\\mathcal{L})$ grows exponentially with the number of labels.\n",
    " \n",
    "If you are curious on the topic of MLC, you are encouraged to read these references:  \n",
    "J. Read, P. Reutemann, B. Pfahringer, and Geoff Holmes. **MEKA: A multi-label/multi-target extension to Weka**. Journal of Machine Learning Research, 17(21):1-5, 2016.  \n",
    "G. Tsoumakas and I. Katakis. **Multi-label classification: An overview**. International Journal on Data Warehousing and Mining, 3(3):1-13, 2007.  \n",
    "G. Tsoumakas, I. Katakis, and I. Vlahavas. **Mining multi-label data**. Data mining and knowledge discovery handbook, pages 667-685. Springer, 2010.\n",
    " \n",
    "Many other variations exist, but for today we'll focus on BR, the most straightforward to implement. What we will start implementing below is a good start if you want to explore what is done in:  \n",
    "J. Read, B. Pfahringer, G. Holmes, and E. Frank. **Classifier chains for multi-label classification**. Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 254-269, 2009.\n",
    "\n",
    "The equivalent approach for LP is found in:  \n",
    "G. Tsoumakas, I. Katakis, and I. Vlahavas. **Random k-labelsets for multi-label classification**. IEEE Transactions on Knowledge and Data Engineering, 23(7):1079-1089, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use a biology dataset from [Elisseeff and Weston 2001]: this dataset contains micro-array expressions and phylogenetic profiles for 2417 yeast genes. Each gene is annotated with a subset of 14 functional categories (e.g. metabolism, energy, etc.) of the top level of the functional catalogue.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice**<br>\n",
    "<ul>\n",
    "\n",
    "<li> find a suitable package to load the file at `yeast.arff`.  <br>\n",
    "    Hint: <a href=https://docs.scipy.org/doc/scipy/reference/io.html>scipy.io</a> and _read the doc_.<br>\n",
    "<li> Store the data in a pandas dataframe.<br>\n",
    "    Hint: columns of classes will be encoded as 'utf-8', we need integers, look for 'str.decode('utf-8')'\n",
    "<li> check dataset: you should have 2417 samples $\\times$ 117 columns (103 features + 14 labels)\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows: 2417\n",
      "ncols: 117\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.float64'>\n",
      "dataframe dimensions: (2417, 117)\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "# Read arff data\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load yeast.arff via dedicated scipy.io function\n",
    "raw_data, metadata = arff.loadarff('../data/yeast/yeast.arff')\n",
    "print(\"nrows:\", len(raw_data))    # 2417\n",
    "print(\"ncols:\", len(raw_data[0])) #  117\n",
    "\n",
    "# Data to pandas, converting unicode columns to integers\n",
    "df = pd.DataFrame(raw_data)\n",
    "# print(df.shape)           # -> (2417, 117)\n",
    "# print(df.head(5))         # for free, we get column names\n",
    "# print(type(df.iloc[0,0])) # -> <class 'bytes'> ## we want to have plain {0,1} integers\n",
    "\n",
    "classes_list = [name for name in df.columns if \"Class\" in name]\n",
    "# print(classes_list)  # -> ['Class1', 'Class2', ... , 'Class14']\n",
    "\n",
    "for col in df[classes_list]:\n",
    "    df[col] = (df[col].str.decode('utf-8').astype(int))\n",
    "\n",
    "print(type(df.iloc[0,0]))  # -> int: as expected\n",
    "print(type(df.iloc[0,15])) # -> float: as expected\n",
    "print(\"dataframe dimensions:\", df.shape)    # -> (2417, 117)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2417"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice**<br>\n",
    "<ul>\n",
    "<li> Manually, fit a SVM classifier for each label in the dataset\n",
    "<li> Apply a cross-validation of 60 âˆ• 40: 60% of datapoints to train the model, 40% to test it  <br>\n",
    "   Remember: it is good practice to <b>randomly shuffle</b> the data, in case the data are ordered w.r.t. some data-dependent criterion.\n",
    "<li> Report some performance measure\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Class1 the cross validation score is 0.6841379310344828\n",
      "for Class2 the cross validation score is 0.5641379310344827\n",
      "for Class3 the cross validation score is 0.5882758620689655\n",
      "for Class4 the cross validation score is 0.6503448275862069\n",
      "for Class5 the cross validation score is 0.696551724137931\n",
      "for Class6 the cross validation score is 0.7496551724137931\n",
      "for Class7 the cross validation score is 0.8303448275862069\n",
      "for Class8 the cross validation score is 0.8068965517241379\n",
      "for Class9 the cross validation score is 0.9255172413793102\n",
      "for Class10 the cross validation score is 0.886896551724138\n",
      "for Class11 the cross validation score is 0.8703448275862069\n",
      "for Class12 the cross validation score is 0.7531034482758621\n",
      "for Class13 the cross validation score is 0.7455172413793105\n",
      "for Class14 the cross validation score is 0.983448275862069\n",
      "* done!\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/code2.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "CVRATIO = 0.4\n",
    "\n",
    "# Features list\n",
    "features_list = [name for name in df.columns if \"Att\" in name]\n",
    "\n",
    "# Shuffle dataset\n",
    "df = df.sample(frac=1, random_state=0)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features_list],\n",
    "    df[classes_list],   # this contains Class1, Class2, ...\n",
    "    test_size=CVRATIO,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "\n",
    "# Loop through each class column\n",
    "for col in classes_list:\n",
    "    # Train\n",
    "    clf.fit(X_train, y_train[col])\n",
    "\n",
    "    # Cross-validation score (optional, instead of just test set)\n",
    "    scores = cross_val_score(clf, X_train, y_train[col], cv=5)\n",
    "\n",
    "    print(f\"for {col} the cross validation score is {np.mean(scores)}\")\n",
    "\n",
    "print(\"* done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear kernel\n",
      "for the  Class1 the cross validation score is 0.7973112719751809\n",
      "*for the  Class2 the cross validation score is 0.6318510858324715\n",
      "*for the  Class3 the cross validation score is 0.7114788004136504\n",
      "*for the  Class4 the cross validation score is 0.7549120992761117\n",
      "*for the  Class5 the cross validation score is 0.7724922440537746\n",
      "*for the  Class6 the cross validation score is 0.7476732161323681\n",
      "*for the  Class7 the cross validation score is 0.8210961737331954\n",
      "*for the  Class8 the cross validation score is 0.7993795243019648\n",
      "*for the  Class9 the cross validation score is 0.9255429162357808\n",
      "*for the  Class10 the cross validation score is 0.8872802481902792\n",
      "*for the  Class11 the cross validation score is 0.8728024819027922\n",
      "*for the  Class12 the cross validation score is 0.7621509824198552\n",
      "*for the  Class13 the cross validation score is 0.7549120992761117\n",
      "*for the  Class14 the cross validation score is 0.9824198552223371\n",
      "* done!\n",
      "rbf kernel\n",
      "for the  Class1 the cross validation score is 0.7766287487073423\n",
      "*for the  Class2 the cross validation score is 0.6514994829369183\n",
      "*for the  Class3 the cross validation score is 0.7425025853154085\n",
      "*for the  Class4 the cross validation score is 0.7735263702171665\n",
      "*for the  Class5 the cross validation score is 0.7849017580144778\n",
      "*for the  Class6 the cross validation score is 0.7766287487073423\n",
      "*for the  Class7 the cross validation score is 0.8345398138572906\n",
      "*for the  Class8 the cross validation score is 0.8014477766287487\n",
      "*for the  Class9 the cross validation score is 0.9327817993795243\n",
      "*for the  Class10 the cross validation score is 0.8965873836608066\n",
      "*for the  Class11 the cross validation score is 0.8841778697001034\n",
      "*for the  Class12 the cross validation score is 0.749741468459152\n",
      "*for the  Class13 the cross validation score is 0.7414684591520165\n",
      "*for the  Class14 the cross validation score is 0.9855222337125129\n",
      "*"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "n=df.shape[0]\n",
    "Att_list = [name for name in df.columns if \"Att\" in name]\n",
    "X=df[Att_list]\n",
    "def shuffle_and_split(X,y,n):\n",
    "    X0,y0 = shuffle(X,y)\n",
    "    Xtrain,Xtest = np.split(X0,[n])\n",
    "    ytrain,ytest = np.split(y0,[n])\n",
    "    return Xtrain, ytrain, Xtest, ytest\n",
    "print(\"Linear kernel\")\n",
    "for col in df[classes_list]:\n",
    "    y=df[col]\n",
    "    Xtrain, ytrain, Xtest, ytest=shuffle_and_split(X,y,int(0.6*n))\n",
    "    yeast_svc = svm.SVC(kernel='linear', C=1)\n",
    "    yeast_svc.fit(Xtrain,ytrain)\n",
    "    print(\"for the \",col,\"the cross validation score is\",  yeast_svc.score(Xtest,ytest))\n",
    "    print('*', end='')\n",
    "print(\" done!\")\n",
    "print(\"rbf kernel\")\n",
    "for col in df[classes_list]:\n",
    "    y=df[col]\n",
    "    Xtrain, ytrain, Xtest, ytest=shuffle_and_split(X,y,int(0.6*n))\n",
    "    yeast_svc = svm.SVC(kernel='rbf', C=1)\n",
    "    yeast_svc.fit(Xtrain,ytrain)\n",
    "    print(\"for the \",col,\"the cross validation score is\",  yeast_svc.score(Xtest,ytest))\n",
    "    print('*', end='')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**, you reached the end of the practice session! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
